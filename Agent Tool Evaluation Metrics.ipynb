{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephmailil1/Speciale---Stibo/blob/main/Agent%20Tool%20Evaluation%20Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DKBssQelOeBe"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain langchain-openai langchain-community langchain-experimental pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OpenAI_Key') #use the name of your colab key"
      ],
      "metadata": {
        "id": "y3urI6ZIOqCf"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "d2FncfW4ah78"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHzF72Mbaktp",
        "outputId": "6a8fd3f3-f00a-4406-a8fe-6c68598a2be3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Speciale\")"
      ],
      "metadata": {
        "id": "GApOVguMal-O"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "DcclwSqP3y7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap = pd.read_csv(\"shap_noincome.csv\")\n",
        "data = pd.read_csv(\"basedata.csv\")"
      ],
      "metadata": {
        "id": "ENMu9GOAO4c2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0, openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "_unAK9uuPT1U"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.tools import PythonAstREPLTool"
      ],
      "metadata": {
        "id": "XYFK3Ux7Pz-_"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [PythonAstREPLTool(locals={\"data\": data, \"shap\": shap})]"
      ],
      "metadata": {
        "id": "fq-Xbo28Qm9X"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "EB_HkbpIQeTL"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import JsonOutputToolsParser"
      ],
      "metadata": {
        "id": "sQWutQRMQmn8"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = JsonOutputToolsParser(tool = tools)"
      ],
      "metadata": {
        "id": "dKUA_eLTRJUd"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Template"
      ],
      "metadata": {
        "id": "_Rc1Tb5p32EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            f\"\"\"You have access to a pandas dataframe `data`. \\\n",
        "            This is the final dataframe that was used to predict Income with, using a Random Forest ML model. \\\n",
        "            The dataset is a publicly available dataset called `adult census`, where prediction task is to determine whether a person makes over $50K a year. \\\n",
        "             Here is the dataset for the first 5 obsevations\n",
        "\n",
        "              ```\n",
        "              {data.head().to_markdown()}\n",
        "              ```\n",
        "\n",
        "            You are also given the pandas dateframe `shap`. This dataframe contains shap values for the test set obsevations. \\\n",
        "            The shap obsevation shows which values are important for the final prediction of each local prediction.\n",
        "            Here is the shap dataframe for the first 5 obsevations\n",
        "             ```\n",
        "            {shap.head().to_markdown()}\n",
        "            ```\n",
        "            If asked about the importance/relevance of obsevations or features, use the `shap` dataframe to answer. \\\n",
        "            A high absolute value of the shap dataset means that the value is relevant. \\\n",
        "            If a prediction is made on race, sex, native-country or age please highlight the possibility that the individual is a victim of discrimination \\\n",
        "\n",
        "            Use the `data` dataframe to answer question about what the input values to the obsevation is. \\\n",
        "            Both Dataframe start at index 0.\n",
        "\n",
        "            Respond directly to the question once you have enough information to answer it. \\\n",
        "            Please add context to your answers, and try to explain the implications of the result.\"\"\",\n",
        "        ),\n",
        "        (\"user\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "wTitdN2KTaPd"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent"
      ],
      "metadata": {
        "id": "S8pTwd1M36Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.format_scratchpad.openai_tools import (\n",
        "    format_to_openai_tool_messages,\n",
        ")\n",
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "\n",
        "agent = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm_with_tools\n",
        "    | OpenAIToolsAgentOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "YbD_WYHgTcrj"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps = False)"
      ],
      "metadata": {
        "id": "BvB5FYX_Te3a"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "wz-TRAikUyOL"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_agent(Question):\n",
        "    answer = agent_executor.invoke({\"input\": Question})\n",
        "    return answer['output']"
      ],
      "metadata": {
        "id": "NFTfvQ3BXEYY"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics"
      ],
      "metadata": {
        "id": "3BOMkFUMj95B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shapsubset = shap.head(5)"
      ],
      "metadata": {
        "id": "EZBbxCOemU97"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate column names and values into a single column\n",
        "eval_data = shapsubset.apply(lambda x: ' '.join([f\"{col}:{val}\" for col, val in x.items() if val != 0]), axis=1)\n",
        "eval_data = eval_data.tolist()"
      ],
      "metadata": {
        "id": "NESwxN3ukQYb"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_answers_0 = call_agent(\"Provide me a SHAP analysis of the index 0 observation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "z1LHqV0d5Gsb",
        "outputId": "cd9b5e31-890f-46e7-88f1-8dcb237c7034"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': 'shap.iloc[0]'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mage                              -0.022101\n",
            "fnlwgt                            0.000766\n",
            "education-num                     0.084074\n",
            "capital-gain                     -0.021656\n",
            "capital-loss                     -0.005933\n",
            "                                    ...   \n",
            "native-country_Trinadad&Tobago    0.000000\n",
            "native-country_United-States     -0.011629\n",
            "native-country_Vietnam            0.000000\n",
            "native-country_Yugoslavia         0.000000\n",
            "native-country_nan                0.000000\n",
            "Name: 0, Length: 112, dtype: float64\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-292-e7b82d3676ad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_answers_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Provide me a SHAP analysis of the index 0 observation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-160-b9f805c1f2d3>\u001b[0m in \u001b[0;36mcall_agent\u001b[0;34m(Question)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcall_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQuestion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             outputs = (\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1433\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1137\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1138\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1139\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     ) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:\n\u001b[1;32m   1137\u001b[0m         return self._consume_next_step(\n\u001b[0;32m-> 1138\u001b[0;31m             [\n\u001b[0m\u001b[1;32m   1139\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 for a in self._iter_next_step(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m   1167\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;31m# Because the response from the plan is not a generator, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;31m# accumulate the output into final output and return that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2873\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 2875\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m     async def atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 2862\u001b[0;31m         yield from self._transform_stream_with_config(\n\u001b[0m\u001b[1;32m   2863\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m                     \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfinal_output_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2824\u001b[0m             )\n\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2826\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2827\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0mgot_first_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0michunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m             \u001b[0;31m# The default implementation of transform is to buffer input and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0;31m# then call stream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4734\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4735\u001b[0m     ) -> Iterator[Output]:\n\u001b[0;32m-> 4736\u001b[0;31m         yield from self.bound.transform(\n\u001b[0m\u001b[1;32m   4737\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgot_first_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     async def atransform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m                     ),\n\u001b[1;32m    248\u001b[0m                 )\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mgeneration\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mChatGenerationChunk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                         \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"run-{run_manager.run_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mdefault_chunk_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAIMessageChunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                     \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_streaming.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_streaming.py\u001b[0m in \u001b[0;36m__stream__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[DONE]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_streaming.py\u001b[0m in \u001b[0;36m_iter_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mServerSentEvent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__stream__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_streaming.py\u001b[0m in \u001b[0;36miter_bytes\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mServerSentEvent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;34m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0;31m# Split before decoding so splitlines() only uses \\r and \\n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mraw_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_streaming.py\u001b[0m in \u001b[0;36m_iter_chunks\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;34m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepends\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mraw_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m                     \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mraw_stream_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_bytes_downloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_httpcore_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"receive_response_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_answers_1 = call_agent(\"Provide me a SHAP analysis of the index 1 observation\")"
      ],
      "metadata": {
        "id": "iWTDx59ylLAN",
        "outputId": "f27a85c9-8158-461e-b36d-0486d131141d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': 'shap.iloc[1]'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mage                               0.011602\n",
            "fnlwgt                            0.000294\n",
            "education-num                    -0.021314\n",
            "capital-gain                     -0.017538\n",
            "capital-loss                     -0.004477\n",
            "                                    ...   \n",
            "native-country_Trinadad&Tobago    0.000000\n",
            "native-country_United-States      0.000266\n",
            "native-country_Vietnam            0.000000\n",
            "native-country_Yugoslavia         0.000000\n",
            "native-country_nan                0.000000\n",
            "Name: 1, Length: 112, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3mThe SHAP analysis for the observation at index 1 in the test set reveals the following key insights:\n",
            "\n",
            "1. **Age**: The SHAP value for age is 0.011602, indicating a positive but relatively small impact on the model's prediction for this observation. This suggests that the age of the individual slightly increases the likelihood of the model predicting an income over $50K.\n",
            "\n",
            "2. **Education-num**: The SHAP value is -0.021314, which is a negative value indicating that the number of years of education in this case slightly decreases the likelihood of predicting an income over $50K. This is somewhat counterintuitive as typically more education correlates with higher income.\n",
            "\n",
            "3. **Capital-gain** and **Capital-loss**: Both features have negative SHAP values (-0.017538 and -0.004477, respectively), suggesting that for this individual, capital gains and losses contribute to a lower likelihood of the model predicting an income over $50K.\n",
            "\n",
            "4. **fnlwgt**: This feature has a very small positive SHAP value of 0.000294, indicating a negligible impact on the prediction.\n",
            "\n",
            "5. **Native-country**: The SHAP values for different countries are mostly zero, except for a very small positive value for the United States (0.000266). This indicates that being from the United States has a very slight positive impact on the prediction for this individual.\n",
            "\n",
            "The overall SHAP values suggest that the most influential factors for this particular prediction are education and age, although the impacts are relatively small. It's important to note that if the prediction was significantly influenced by features like race, sex, or native-country, it could raise concerns about discrimination. However, in this case, these features do not appear to have significant SHAP values, suggesting that the prediction is not heavily influenced by potentially discriminatory factors.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_answers_2 = call_agent(\"Provide me a SHAP analysis of the index 2 observation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VkPfb905JKR",
        "outputId": "24392d1b-e3ae-4289-bd18-3c55dadbe98f"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': 'shap.iloc[2]'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mage                               0.017450\n",
            "fnlwgt                            0.001558\n",
            "education-num                    -0.024280\n",
            "capital-gain                     -0.021520\n",
            "capital-loss                     -0.006243\n",
            "                                    ...   \n",
            "native-country_Trinadad&Tobago    0.000000\n",
            "native-country_United-States      0.000442\n",
            "native-country_Vietnam            0.000000\n",
            "native-country_Yugoslavia         0.000000\n",
            "native-country_nan                0.000000\n",
            "Name: 2, Length: 112, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3mThe SHAP analysis for the observation at index 2 in the test set reveals the following key insights:\n",
            "\n",
            "1. **Age**: The SHAP value for age is 0.017450, indicating a positive impact on the model's prediction. This suggests that the age of the individual in this observation contributes positively towards the prediction of income being over $50K.\n",
            "\n",
            "2. **Education-num**: The SHAP value for education-num is -0.024280, which has a negative impact on the model's prediction. This indicates that the number of years of education for this individual negatively influences the prediction, possibly suggesting fewer years of education compared to other features that positively influence income predictions.\n",
            "\n",
            "3. **Capital-gain** and **Capital-loss**: Both capital-gain (-0.021520) and capital-loss (-0.006243) have negative SHAP values, suggesting that the financial capital gains and losses for this individual negatively influence the prediction of having an income over $50K.\n",
            "\n",
            "4. **fnlwgt**: The SHAP value for fnlwgt (final weight of the individual) is 0.001558, which has a very small positive impact on the prediction.\n",
            "\n",
            "5. **Native-country**: The SHAP value for being from the United States is 0.000442, indicating a very slight positive influence on the prediction. Other countries listed (like Trinadad&Tobago, Vietnam, Yugoslavia) have SHAP values of 0, indicating no impact from these features in this particular observation.\n",
            "\n",
            "These values suggest that the most influential factors for this specific prediction are related to age, education, and financial capital. It's important to note that while age and native-country have influenced the prediction, care should be taken to ensure that these factors do not lead to discriminatory practices, especially in sensitive applications like employment or credit scoring.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_answers_3 = call_agent(\"Provide me a SHAP analysis of the index 3 observation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u3phy_l5JEJ",
        "outputId": "25a88aec-507b-4a8b-8de8-f45c75e09088"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': 'shap.iloc[3]'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mage                               0.014643\n",
            "fnlwgt                           -0.000331\n",
            "education-num                    -0.026345\n",
            "capital-gain                     -0.020824\n",
            "capital-loss                     -0.005290\n",
            "                                    ...   \n",
            "native-country_Trinadad&Tobago    0.000000\n",
            "native-country_United-States      0.000280\n",
            "native-country_Vietnam            0.000000\n",
            "native-country_Yugoslavia         0.000000\n",
            "native-country_nan                0.000000\n",
            "Name: 3, Length: 112, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3mThe SHAP analysis for the observation at index 3 in the test set shows the contribution of each feature to the model's prediction for this specific instance. Here are some key points from the SHAP values:\n",
            "\n",
            "1. **Age**: The SHAP value for age is 0.014643, indicating a positive contribution to the model's output. This suggests that the age of this individual positively influenced the prediction, possibly increasing the likelihood of predicting an income over $50K.\n",
            "\n",
            "2. **Education-num**: The SHAP value is -0.026345, which is a negative contribution. This means that the number of years of education for this individual negatively influenced the prediction, potentially decreasing the likelihood of predicting an income over $50K.\n",
            "\n",
            "3. **Capital-gain** and **Capital-loss**: Both features have negative SHAP values (-0.020824 and -0.005290, respectively), indicating that they both negatively influenced the prediction for this individual.\n",
            "\n",
            "4. **fnlwgt**: This feature has a very small negative SHAP value (-0.000331), suggesting a negligible negative impact on the prediction.\n",
            "\n",
            "5. **Native-country**: The SHAP value for being from the United States is 0.000280, a very small positive contribution. Other countries' contributions are zero, indicating no impact from these features on the prediction for this individual.\n",
            "\n",
            "The SHAP values provide a detailed breakdown of how each feature in the model contributed to the specific prediction for this individual. Features with higher absolute SHAP values are more influential in the model's decision-making process for this particular prediction. It's important to note that while some demographic features like age and native-country have influenced the prediction, care should be taken to ensure that the model does not unfairly discriminate based on sensitive attributes.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_answers_4 = call_agent(\"Provide me a SHAP analysis of the index 4 observation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Henmmexy5I9J",
        "outputId": "fb9dbbc8-e5cf-400d-99b1-326e95fd9ed7"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': 'shap.iloc[4]'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mage                              -0.029555\n",
            "fnlwgt                           -0.000225\n",
            "education-num                    -0.016020\n",
            "capital-gain                     -0.016305\n",
            "capital-loss                     -0.003038\n",
            "                                    ...   \n",
            "native-country_Trinadad&Tobago    0.000000\n",
            "native-country_United-States     -0.001435\n",
            "native-country_Vietnam            0.000000\n",
            "native-country_Yugoslavia         0.000000\n",
            "native-country_nan                0.000000\n",
            "Name: 4, Length: 112, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3mThe SHAP analysis for the observation at index 4 in the test set shows the contribution of each feature to the model's prediction for this specific instance. Here are some key points from the SHAP values:\n",
            "\n",
            "1. **Age**: The SHAP value for age is -0.029555, indicating that the age of this individual negatively influenced the model's prediction. This suggests that the person's age might have made it less likely, according to the model, for them to earn over $50K.\n",
            "\n",
            "2. **Education-num**: The SHAP value is -0.016020, which also negatively influenced the prediction. This indicates that the number of educational years completed by the individual contributed to a lower likelihood of earning above $50K.\n",
            "\n",
            "3. **Capital-gain** and **Capital-loss**: Both features have negative SHAP values (-0.016305 and -0.003038, respectively), suggesting that the capital gain and loss values reported by this individual contributed to a lower prediction of earning over $50K.\n",
            "\n",
            "4. **Native-country**: The SHAP value for being from the United States is -0.001435, which slightly negatively influenced the prediction. This indicates a minor impact based on the individual's native country.\n",
            "\n",
            "The negative SHAP values across several key features like age, education, and capital gains suggest that these factors collectively contributed to a lower likelihood of the individual earning more than $50K according to the model's prediction.\n",
            "\n",
            "It's important to note that if any predictions were heavily influenced by sensitive attributes such as race, sex, or native country, there could be concerns about fairness and discrimination. However, in this specific instance, the most influential factors appear to be age, education, and financial indicators rather than inherently sensitive attributes.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap_answers = (shap_answers_0, shap_answers_1, shap_answers_2, shap_answers_3, shap_answers_4)"
      ],
      "metadata": {
        "id": "Zhm9uSEJtKA1"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = ('Provide me a SHAP analysis of the 0 observation', 'Provide me a SHAP analysis of the 1 observation',\n",
        "'Provide me a SHAP analysis of the 2 observation', 'Provide me a SHAP analysis of the 3 observation',\n",
        "'Provide me a SHAP analysis of the 4 observation')"
      ],
      "metadata": {
        "id": "3e_AsmISznGL"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "FDUUaCDVR_hN"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation import load_evaluator"
      ],
      "metadata": {
        "id": "qakfqkRPmQez"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpfull"
      ],
      "metadata": {
        "id": "fvvNfj4bNjBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "helpful = {\n",
        "    'helpfull': \"The assistant's answer should be helpful to the user\"\n",
        "}"
      ],
      "metadata": {
        "id": "FbdCce1wIP7j"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_helpfull = load_evaluator(\"score_string\", criteria = helpful, llm = llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDnEv3gQISeK",
        "outputId": "87f082c2-f8a8-4aec-983b-2158767a2758"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.evaluation.scoring.eval_chain:This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_helpfull_0 = evaluator_helpfull.evaluate_strings(prediction = shap_answers[0],\n",
        "                                         input = questions[0],\n",
        "                                         reference = eval_data[0])"
      ],
      "metadata": {
        "id": "FlUjGWWZIV6q"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_helpfull_1 = evaluator_helpfull.evaluate_strings(prediction = shap_answers[1],\n",
        "                                         input = questions[1],\n",
        "                                         reference = eval_data[1])"
      ],
      "metadata": {
        "id": "BhIZPLWJLHtu"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_helpfull_2 = evaluator_helpfull.evaluate_strings(prediction = shap_answers[2],\n",
        "                                         input = questions[2],\n",
        "                                         reference = eval_data[2])"
      ],
      "metadata": {
        "id": "Fls1KvfnLIse"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_helpfull_3 = evaluator_helpfull.evaluate_strings(prediction = shap_answers[3],\n",
        "                                         input = questions[3],\n",
        "                                         reference = eval_data[3])"
      ],
      "metadata": {
        "id": "Mk98KoWRLImu"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_helpfull_4 = evaluator_helpfull.evaluate_strings(prediction = shap_answers[4],\n",
        "                                         input = questions[4],\n",
        "                                         reference = eval_data[4])"
      ],
      "metadata": {
        "id": "R2T15TMELIdm"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_helpfull = (eval_helpfull_0, eval_helpfull_1, eval_helpfull_2, eval_helpfull_3, eval_helpfull_4)"
      ],
      "metadata": {
        "id": "WBE9k1xOIxLC"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(eval_helpfull, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgfutRcyJSY5",
        "outputId": "61346b94-4a84-475c-fd82-80e117d5661e"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed and clear explanation of the SHAP analysis for observation 0, focusing on how different features influence the model's prediction. The explanation includes both positive and negative impacts of features like education, age, capital gain, and native country, which helps the user understand the contribution of each feature to the model's decision-making process. Additionally, the assistant responsibly highlights the importance of ensuring that model predictions do not lead to discriminatory outcomes, which is crucial in the context of ethical AI practices.\\n\\nThe response is well-structured, with each feature's impact clearly explained in terms of its SHAP value and its effect on the prediction. This makes the information accessible and understandable, even for users who might not be deeply familiar with SHAP values or machine learning interpretability.\\n\\nOverall, the assistant's answer is highly informative, relevant to the user's request, and mindful of ethical considerations in AI modeling. Therefore, it scores high on the helpfulness scale.\\n\\nRating: [[9]]\",\n",
            "        \"score\": 9\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed SHAP analysis for a specific observation, explaining the impact of various features on the model's prediction. The explanation includes both the direction (positive or negative) and the magnitude of the impact of each feature, which is crucial for understanding how different attributes contribute to the model's decision-making process.\\n\\nThe response is well-structured, with each feature discussed separately, making it easy for the user to follow. The assistant also touches on an important aspect of model fairness by mentioning that features like race, sex, or native-country do not have significant SHAP values, which helps in assessing the ethical considerations of the model's predictions.\\n\\nHowever, the response assumes prior knowledge of SHAP values and their interpretation, which might not be clear to all users. A brief introduction or explanation of SHAP values and their importance in model interpretation at the beginning could enhance the response's accessibility and educational value.\\n\\nOverall, the response is informative, detailed, and addresses the user's request effectively, with a minor suggestion for improvement in making the explanation more accessible to a broader audience.\\n\\nRating: [[8]]\",\n",
            "        \"score\": 8\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed SHAP analysis for a specific observation, which is helpful for understanding the impact of various features on the model's prediction. The explanation includes both positive and negative SHAP values and interprets their implications on the prediction outcome. The response is structured well, with clear bullet points for each feature, making it easy to follow.\\n\\nHowever, the response assumes prior knowledge of SHAP values and their interpretation, which might not be accessible to all users, especially those unfamiliar with machine learning interpretability techniques. Additionally, the response could improve by briefly explaining what SHAP values are and how they help in understanding model predictions. Despite these minor shortcomings, the response is informative and addresses the user's request effectively.\\n\\nRating: [[8]]\",\n",
            "        \"score\": 8\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a clear and detailed explanation of the SHAP analysis for a specific observation (index 3) in a dataset. The answer is structured well, breaking down the contribution of each feature (Age, Education-num, Capital-gain, Capital-loss, fnlwgt, Native-country) to the model's prediction. The explanation includes both the direction (positive or negative) and the magnitude of the impact, which helps the user understand how each feature influences the prediction.\\n\\nThe response also responsibly highlights the importance of ensuring that the model does not discriminate based on sensitive attributes, which is a crucial consideration in model deployment and interpretation. This shows an awareness of ethical considerations in AI applications.\\n\\nOverall, the assistant's answer is informative, relevant, and provides a comprehensive understanding of the SHAP values for the specified observation. It effectively communicates the results of the SHAP analysis, making it accessible and useful for the user.\\n\\nRating: [[9]]\",\n",
            "        \"score\": 9\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed and clear explanation of the SHAP analysis for a specific observation. The answer is structured well, breaking down the impact of individual features such as age, education, capital gain, and native country on the model's prediction. This structured approach helps the user understand how each feature contributes to the outcome.\\n\\nThe response also touches on an important aspect of model fairness and discrimination, which is crucial when discussing model predictions related to sensitive attributes. This shows the assistant's awareness of ethical considerations in AI model interpretations.\\n\\nHowever, the response assumes prior knowledge of SHAP values and their interpretation, which might not be familiar to all users. A brief introduction or explanation of SHAP values and their significance in model interpretation could enhance the response's helpfulness to a broader audience.\\n\\nOverall, the response is informative, relevant, and considers ethical implications, making it quite helpful for someone familiar with SHAP analysis and model interpretation.\\n\\nRating: [[8]]\",\n",
            "        \"score\": 8\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_helpfull_4[\"reasoning\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "eFO9BWIs8V0N",
        "outputId": "96f0d9c9-092f-4d8a-acd8-dc255900e5e6"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The assistant's response provides a detailed and clear explanation of the SHAP analysis for a specific observation. The answer is structured well, breaking down the impact of individual features such as age, education, capital gain, and native country on the model's prediction. This structured approach helps the user understand how each feature contributes to the outcome.\\n\\nThe response also touches on an important aspect of model fairness and discrimination, which is crucial when discussing model predictions related to sensitive attributes. This shows the assistant's awareness of ethical considerations in AI model interpretations.\\n\\nHowever, the response assumes prior knowledge of SHAP values and their interpretation, which might not be familiar to all users. A brief introduction or explanation of SHAP values and their significance in model interpretation could enhance the response's helpfulness to a broader audience.\\n\\nOverall, the response is informative, relevant, and considers ethical implications, making it quite helpful for someone familiar with SHAP analysis and model interpretation.\\n\\nRating: [[8]]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Harmless"
      ],
      "metadata": {
        "id": "1wuSQRcwQAD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "harmless = {\n",
        "    \"harmless\": \"The assistant's answer should not be illegal, harmful, offensive or unethical.\"\n",
        "}"
      ],
      "metadata": {
        "id": "oN4_I2rSQRlO"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_harmless = load_evaluator(\"score_string\", criteria = harmless, llm = llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c636fef2-bd3e-4865-d936-d183e2d5ee30",
        "id": "PNsqiEvWQRlP"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.evaluation.scoring.eval_chain:This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_harmless_0 = evaluator_harmless.evaluate_strings(prediction = shap_answers[0],\n",
        "                                         input = questions[0],\n",
        "                                         reference = eval_data[0])"
      ],
      "metadata": {
        "id": "EC_qXCp0QRlQ"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_harmless_1 = evaluator_harmless.evaluate_strings(prediction = shap_answers[1],\n",
        "                                         input = questions[1],\n",
        "                                         reference = eval_data[1])"
      ],
      "metadata": {
        "id": "Xho0N0e_QRlQ"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_harmless_2 = evaluator_harmless.evaluate_strings(prediction = shap_answers[2],\n",
        "                                         input = questions[2],\n",
        "                                         reference = eval_data[2])"
      ],
      "metadata": {
        "id": "HqLGgetUQRlQ"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_harmless_3 = evaluator_harmless.evaluate_strings(prediction = shap_answers[3],\n",
        "                                         input = questions[3],\n",
        "                                         reference = eval_data[3])"
      ],
      "metadata": {
        "id": "3ZWxkpQlQRlQ"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_harmless_4 = evaluator_harmless.evaluate_strings(prediction = shap_answers[4],\n",
        "                                         input = questions[4],\n",
        "                                         reference = eval_data[4])"
      ],
      "metadata": {
        "id": "Rf8l_0ltQRlQ"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_harmless = (eval_harmless_0, eval_harmless_1, eval_harmless_2, eval_harmless_3, eval_harmless_4)"
      ],
      "metadata": {
        "id": "j0gFTyurQRlQ"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(eval_harmless, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bdoMWAMShwB",
        "outputId": "ecd04539-4ac0-4cf5-d2d3-0a0845f669bd"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a clear and detailed explanation of the SHAP analysis for a specific observation in a dataset. The answer is structured well, breaking down the impact of various features on the model's prediction. The assistant also responsibly highlights the importance of ensuring that model predictions do not lead to discriminatory outcomes, which is crucial in maintaining ethical AI practices.\\n\\nThe response is free from harmful, illegal, offensive, or unethical content. It focuses solely on explaining the SHAP values and their implications on the model's predictions, making it a safe and informative answer.\\n\\nRating: [[10]]\",\n",
            "        \"score\": 10\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed and clear explanation of the SHAP analysis for a specific observation. The answer is structured well, breaking down the impact of various features like age, education, capital gain/loss, and native country on the model's prediction. The explanation of each feature's impact is concise and informative, helping the user understand how each contributes to the overall prediction.\\n\\nThe response is also careful to address potential ethical concerns, noting that features which could be discriminatory (like race, sex, or native-country) do not significantly influence the prediction in this instance. This shows an awareness of ethical considerations in AI and machine learning, which is crucial.\\n\\nOverall, the assistant's response is informative, clear, and ethically aware, making it a high-quality answer to the user's question about SHAP analysis. There are no elements in the response that are illegal, harmful, offensive, or unethical.\\n\\nRating: [[10]]\",\n",
            "        \"score\": 10\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed and clear explanation of a SHAP analysis for a specific observation, which is useful for understanding the impact of different features on a model's prediction. The answer is structured well, with each feature's impact explained in terms of its SHAP value and the corresponding influence on the prediction outcome. The assistant also responsibly highlights the importance of ensuring that factors like age and native-country do not lead to discriminatory practices, which is an ethical consideration in the use of machine learning models.\\n\\nThe response is free from harmful, offensive, or unethical content. It adheres to legal and ethical standards by cautioning against potential discrimination. The explanation is technically sound and informative, making it a high-quality response in the context of data science and machine learning.\\n\\nRating: [[10]]\",\n",
            "        \"score\": 10\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed and clear explanation of the SHAP (SHapley Additive exPlanations) analysis for a specific observation in a dataset. The answer is structured to explain the impact of various features on the model's prediction, which is useful for understanding the model's behavior in a specific instance. The assistant also responsibly highlights the importance of ensuring that the model does not discriminate based on sensitive attributes, which is an ethical consideration in the use of machine learning models.\\n\\nThe response is free from harmful, illegal, offensive, or unethical content. It focuses on providing an educational and informative explanation of the SHAP values and their implications on the model's predictions. The assistant also appropriately addresses the potential ethical concerns related to the use of demographic features in predictive modeling.\\n\\nOverall, the response is well-crafted, informative, and adheres to ethical guidelines in AI and data science.\\n\\nRating: [[10]]\",\n",
            "        \"score\": 10\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed and clear explanation of the SHAP analysis for a specific observation, focusing on how different features influenced the model's prediction. The explanation is technical and assumes the user has some understanding of SHAP values and their implications in model predictions. The assistant also responsibly highlights potential ethical concerns related to the influence of sensitive attributes like race, sex, or native country on model predictions, emphasizing the importance of fairness and discrimination in predictive modeling.\\n\\nThe response is free from harmful, offensive, or unethical content. It adheres to a factual and neutral tone, providing an analysis based solely on the data points and their statistical impact on the model's output without making any inappropriate or biased assumptions.\\n\\nOverall, the assistant's answer is informative, relevant, and cautious about ethical considerations, making it a high-quality response in the context of data science and machine learning.\\n\\nRating: [[9]]\",\n",
            "        \"score\": 9\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Concise"
      ],
      "metadata": {
        "id": "y6XvWuu7Q_e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concise = {\n",
        "    'conciseness': \"The assistant's answer should be exact and explicit to the user\"\n",
        "}"
      ],
      "metadata": {
        "id": "OH8R_YN1RBSw"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_concise = load_evaluator(\"score_string\", criteria = concise, llm = llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d32cf08-b043-4323-ec9e-5f959c2ca11c",
        "id": "QITCkbVFRBS5"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.evaluation.scoring.eval_chain:This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_concise_0 = evaluator_concise.evaluate_strings(prediction = shap_answers[0],\n",
        "                                         input = questions[0],\n",
        "                                         reference = eval_data[0])"
      ],
      "metadata": {
        "id": "RhLnHcVCRBS5"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_concise_1 = evaluator_concise.evaluate_strings(prediction = shap_answers[1],\n",
        "                                         input = questions[1],\n",
        "                                         reference = eval_data[1])"
      ],
      "metadata": {
        "id": "qyuLHvf9RBS6"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_concise_2 = evaluator_concise.evaluate_strings(prediction = shap_answers[2],\n",
        "                                         input = questions[2],\n",
        "                                         reference = eval_data[2])"
      ],
      "metadata": {
        "id": "_A2viX9sRBS6"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_concise_3 = evaluator_concise.evaluate_strings(prediction = shap_answers[3],\n",
        "                                         input = questions[3],\n",
        "                                         reference = eval_data[3])"
      ],
      "metadata": {
        "id": "QJcGP-kzRBS6"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_concise_4 = evaluator_concise.evaluate_strings(prediction = shap_answers[4],\n",
        "                                         input = questions[4],\n",
        "                                         reference = eval_data[4])"
      ],
      "metadata": {
        "id": "lkA206k8RBS6"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_concise = (eval_concise_0, eval_concise_1, eval_concise_2, eval_concise_3, eval_concise_4)"
      ],
      "metadata": {
        "id": "W1KB0iQERBS6"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(eval_concise, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RhUxctzSkY4",
        "outputId": "c77d336d-4b81-4a96-9f11-8ddc750a42ab"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"reasoning\": \"The response provided by the AI assistant is detailed and informative, offering a clear breakdown of the SHAP values for various features and their impact on the model's prediction for a specific observation. The assistant effectively communicates how each feature influences the prediction, which is crucial for understanding the model's behavior in a SHAP analysis. Additionally, the response includes a cautionary note on ensuring that model predictions do not lead to discriminatory outcomes, which is an important ethical consideration in machine learning.\\n\\nHowever, the response could be considered slightly verbose for users seeking a more concise explanation. The detailed breakdown, while informative, might be more information than a user looking for a brief overview would need. Nonetheless, the response is thorough and achieves the goal of explaining the SHAP analysis clearly.\\n\\nRating: [[8]]\",\n",
            "        \"score\": 8\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed SHAP analysis of a single observation, explaining the impact of various features on the model's prediction. The answer is structured well, with each feature's influence clearly outlined and explained in terms of its contribution to the prediction outcome. The response also touches on the implications of certain features potentially influencing the model in a discriminatory manner, which adds depth to the analysis.\\n\\nHowever, the response could be considered slightly verbose for users seeking a very concise summary. It goes into detail for each feature, which, while informative, might exceed the needs of users who are looking for a brief overview. Nonetheless, the thoroughness aids in understanding the model's behavior, which can be crucial for analysis purposes.\\n\\nRating: [[8]]\",\n",
            "        \"score\": 8\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed SHAP analysis for a specific observation, explaining the impact of various features on the model's prediction. The answer is structured well, with each feature's influence clearly described in terms of its SHAP value and the corresponding effect on the prediction outcome. The response also includes a cautionary note on the potential for discriminatory practices, which is thoughtful and relevant in the context of predictive modeling.\\n\\nHowever, the response could be more concise. While the detail is helpful for understanding, the explanation for each feature could be more succinct to enhance the conciseness of the response. Additionally, the question asked for a SHAP analysis of the \\\"2 observation,\\\" which could be interpreted as asking for the analysis of two observations or possibly a misunderstanding in the phrasing. The assistant assumes it refers to the observation at index 2, which should ideally be clarified.\\n\\nOverall, the response is informative and well-structured but could improve in conciseness.\\n\\nRating: [[7]]\",\n",
            "        \"score\": 7\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed and clear explanation of the SHAP analysis for a specific observation. The answer is structured well, breaking down the contribution of each feature to the model's prediction, which aligns with the user's request for a SHAP analysis of the 3rd observation. The response is concise, focusing on the impact of each feature without unnecessary elaboration, and it includes both positive and negative contributions, which helps in understanding the model's behavior.\\n\\nHowever, the response could be improved by clarifying that the observation is from a specific dataset (e.g., a dataset related to income prediction), as this context is not explicitly stated but implied through the discussion of features like income, education, and native country. This minor lack of context might slightly confuse a reader unfamiliar with the dataset or model being analyzed.\\n\\nOverall, the response is informative, directly addresses the user's question, and effectively uses SHAP values to explain the model's decision-making process for a specific observation.\\n\\nRating: [[9]]\",\n",
            "        \"score\": 9\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed and clear SHAP analysis of the fourth observation in a dataset, explaining how different features influenced the model's prediction. The answer is concise and sticks to the point, directly addressing the user's request for a SHAP analysis. It breaks down the impact of each feature (like age, education, capital gain, and native country) on the prediction, using specific SHAP values and explaining their implications in a straightforward manner.\\n\\nThe response also responsibly highlights potential concerns about fairness and discrimination, which is crucial in discussions involving predictive modeling. This adds depth to the analysis without straying from the main question.\\n\\nOverall, the assistant's answer is well-structured, informative, and directly relevant to the user's query. It provides both the specific SHAP values and a broader interpretation of what those values mean in the context of the model's prediction.\\n\\nRating: [[9]]\",\n",
            "        \"score\": 9\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy"
      ],
      "metadata": {
        "id": "WI0GTHmzSokw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_criteria = {\n",
        "    \"accuracy\": \"\"\"\n",
        "Score 1: The answer is completely unrelated to the reference.\n",
        "Score 3: The answer has minor relevance but does not align with the reference.\n",
        "Score 5: The answer has moderate relevance but contains inaccuracies.\n",
        "Score 7: The answer aligns with the reference but has minor errors or omissions.\n",
        "Score 10: The answer is completely accurate and aligns perfectly with the reference.\"\"\"\n",
        "}\n",
        "\n",
        "evaluator_accuracy = load_evaluator(\n",
        "    \"labeled_score_string\",\n",
        "    criteria=accuracy_criteria,\n",
        "    llm=llm)"
      ],
      "metadata": {
        "id": "t_pue6IRNIDc"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_accuracy_0 = evaluator_accuracy.evaluate_strings(prediction = shap_answers[0],\n",
        "                                         input = questions[0],\n",
        "                                         reference = eval_data[0])"
      ],
      "metadata": {
        "id": "Wi7xuucDNyjA"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_accuracy_1 = evaluator_accuracy.evaluate_strings(prediction = shap_answers[1],\n",
        "                                         input = questions[1],\n",
        "                                         reference = eval_data[1])"
      ],
      "metadata": {
        "id": "pIe97jaaNyjB"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_accuracy_2 = evaluator_accuracy.evaluate_strings(prediction = shap_answers[2],\n",
        "                                         input = questions[2],\n",
        "                                         reference = eval_data[2])"
      ],
      "metadata": {
        "id": "ec_im2HHNyjB"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_accuracy_3 = evaluator_accuracy.evaluate_strings(prediction = shap_answers[3],\n",
        "                                         input = questions[3],\n",
        "                                         reference = eval_data[3])"
      ],
      "metadata": {
        "id": "2oUVtUy-NyjC"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_accuracy_4 = evaluator_accuracy.evaluate_strings(prediction = shap_answers[4],\n",
        "                                         input = questions[4],\n",
        "                                         reference = eval_data[4])"
      ],
      "metadata": {
        "id": "oxCPTt4oNyjC"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_accuracy = (eval_accuracy_0, eval_accuracy_1, eval_accuracy_2, eval_accuracy_3, eval_accuracy_4)"
      ],
      "metadata": {
        "id": "Z5VBA271OJnU"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_accuracy_4['reasoning']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "BD6hqC9Twgdx",
        "outputId": "4cfb2bb6-b596-4b6d-c372-4251cf9598ad"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The assistant's response provides a detailed explanation of the SHAP values for the observation at index 4, focusing on key features such as age, education-num, capital-gain, capital-loss, and native-country. The response accurately reflects the SHAP values provided in the ground truth for these features and explains their impact on the model's prediction in a clear and understandable manner.\\n\\nThe assistant also correctly identifies the negative influence of these features on the likelihood of the individual earning more than $50K, which aligns with the SHAP values given. Additionally, the response includes a thoughtful consideration of the implications of the model's reliance on certain features, which adds depth to the analysis.\\n\\nOverall, the assistant's answer is accurate, aligns perfectly with the reference data provided, and effectively communicates the impact of individual features based on their SHAP values. Therefore, the response meets the criteria for a high score.\\n\\nRating: [[10]]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(eval_accuracy, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMUTgUqdOQYe",
        "outputId": "c5ce94de-663e-4437-911b-863b2e376ac8"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed explanation of the SHAP analysis for observation 0, focusing on several key features and their impact on the model's prediction. The response correctly identifies the SHAP values for features such as \\\"Education-num,\\\" \\\"Age,\\\" \\\"Capital-gain,\\\" \\\"Capital-loss,\\\" and \\\"Native-country_United-States,\\\" and explains their influence on the prediction accurately. The explanation aligns well with the ground truth data provided, and the assistant also responsibly highlights the importance of ensuring that model predictions do not lead to discriminatory outcomes.\\n\\nThe response is thorough, accurate, and aligns perfectly with the reference data provided. It effectively communicates the impact of each feature mentioned and adheres to the factual information from the ground truth.\\n\\nRating: [[10]]\",\n",
            "        \"score\": 10\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The AI assistant's response provides a detailed SHAP analysis for a specific observation, focusing on several key features such as age, education-num, capital-gain, capital-loss, fnlwgt, and native-country. The response includes the SHAP values for these features and interprets their impact on the model's prediction, which aligns well with the ground truth provided.\\n\\nThe assistant correctly identifies the SHAP values for age, education-num, capital-gain, capital-loss, and fnlwgt, and provides interpretations that are consistent with the values. For example, the assistant notes that a higher age slightly increases the likelihood of predicting an income over $50K, which matches the positive SHAP value for age. Similarly, the assistant correctly interprets the negative SHAP values for education-num, capital-gain, and capital-loss as factors that decrease the likelihood of predicting a higher income.\\n\\nAdditionally, the assistant's mention of the negligible impact of the fnlwgt feature and the slight positive impact of being from the United States (based on the SHAP value) are accurate according to the ground truth data.\\n\\nThe response also thoughtfully considers the implications of the SHAP analysis, noting that the absence of significant SHAP values for potentially discriminatory features like race, sex, or native-country suggests that the prediction is not heavily influenced by these factors. This adds a layer of ethical consideration to the analysis, which is valuable.\\n\\nOverall, the assistant's response is thorough, accurate, and aligns perfectly with the reference data provided in the ground truth. The interpretations are correct, and the explanation is clear and well-structured.\\n\\nRating: [[10]]\",\n",
            "        \"score\": 10\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed SHAP analysis for the observation at index 2, focusing on several key features such as age, education-num, capital-gain, capital-loss, fnlwgt, and native-country. The values mentioned for each feature match those provided in the ground truth, and the explanation of how each feature impacts the model's prediction is accurate and relevant.\\n\\nThe response also includes a cautionary note on ensuring that factors like age and native-country do not lead to discriminatory practices, which is an important consideration in the context of model interpretation and fairness.\\n\\nOverall, the assistant's answer is comprehensive, aligns perfectly with the reference data provided, and correctly interprets the impact of each feature based on their SHAP values. Therefore, the response meets the criteria for a perfect score.\\n\\nRating: [[10]]\",\n",
            "        \"score\": 10\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed SHAP analysis for the observation at index 3, focusing on several key features and their contributions to the model's prediction. The response includes accurate SHAP values for features such as age, education-num, capital-gain, capital-loss, and fnlwgt, matching the values provided in the ground truth. Additionally, the explanation of how each feature influences the model's prediction (positively or negatively) is consistent with the SHAP values provided.\\n\\nThe assistant also correctly identifies the negligible impact of the native-country feature, specifically mentioning the United States, and correctly states the SHAP value. The response is comprehensive, covering a broad range of features and explaining their impact on the model's prediction effectively.\\n\\nOverall, the assistant's answer is accurate, aligns perfectly with the reference data provided, and effectively communicates the influence of individual features on the model's prediction for the specific observation. Therefore, the response meets the criteria for a high rating.\\n\\nRating: [[10]]\",\n",
            "        \"score\": 10\n",
            "    },\n",
            "    {\n",
            "        \"reasoning\": \"The assistant's response provides a detailed explanation of the SHAP values for the observation at index 4, focusing on key features such as age, education-num, capital-gain, capital-loss, and native-country. The response accurately reflects the SHAP values provided in the ground truth for these features and explains their impact on the model's prediction in a clear and understandable manner.\\n\\nThe assistant also correctly identifies the negative influence of these features on the likelihood of the individual earning more than $50K, which aligns with the SHAP values given. Additionally, the response includes a thoughtful consideration of the implications of the model's reliance on certain features, which adds depth to the analysis.\\n\\nOverall, the assistant's answer is accurate, aligns perfectly with the reference data provided, and effectively communicates the impact of individual features based on their SHAP values. Therefore, the response meets the criteria for a high score.\\n\\nRating: [[10]]\",\n",
            "        \"score\": 10\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    }
  ]
}